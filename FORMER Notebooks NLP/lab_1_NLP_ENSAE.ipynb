{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Pvrzu4LZDwo"
      },
      "source": [
        "# Lab session 1 \n",
        "# An introduction to textual data\n",
        "\n",
        "## Lecture takeaways \n",
        "\n",
        "- The Why of NLP\n",
        "- What is NLP ? the four challenges of NLP\n",
        "- NLP in three pipelines\n",
        "\n",
        "cf. https://nlp-ensae.github.io/files/NLP-ENSAE-lecture-1.pdf\n",
        "\n",
        "## Lab session Prerequisites\n",
        "\n",
        "- Python \n",
        "- Pandas \n",
        "\n",
        "For those not familiar with pandas https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html \n",
        "\n",
        "## Lab session in a nushell \n",
        "\n",
        "- Grasping a dataset \n",
        "- Basic Tokenization (Word Segmentation) of a dataset\n",
        "(Compute Vocabulary and Zipf's law)\n",
        "- Regex \n",
        "- Hands on some processing tools (POS, NER, ...) \n",
        "\n",
        "## Resources : \n",
        "\n",
        "- NLTK : https://www.nltk.org/api/nltk.tokenize.html \n",
        "- PANDAS : https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\n",
        "- SPACY : https://spacy.io/usage/spacy-101 \n",
        "\n",
        "\n",
        "## Database\n",
        "\n",
        "We will use the following database:\n",
        "https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/01/PLOS_narrativity.csv.zip\n",
        "\n",
        "This database is used in a scientific article about the importance of narrativity in the citation frequency of climate change scientific articles.  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167983  \n",
        "\n",
        "\n",
        "## Tasks\n",
        "\n",
        "### 1. Basic preprocessing\n",
        "#### 1.1 Open the database. Generate simple statistics about the abstracts. How many unique articles are there? What is the mean length of abstracts in characters? \n",
        "#### 1.2 Generate simple statistics about the annotators' data for each article. Do the annotations seem consistent? \n",
        "\n",
        "### 2. Word-level preprocessing\n",
        "#### 2.1 Split the abstracts into list of words. How many different words are there in the vocabulary? \n",
        "#### 2.2 Split the abstracts into list of words using three different tokenizers from nltk. What is the difference in terms of number of words? What do you think has changed?\n",
        "#### 2.3 Check if Zipf's law applies. \n",
        "\n",
        "### 3. Domain specificity and regex\n",
        "#### 3.1 Use regex to retrieve numbers (ints, floats, %, years, ...) using a regex. \n",
        "#### 3.2 How many percent of characters are numbers (as defined above) in a given abstract? \n",
        "#### 3.3 Is there any relationship between the percentage of numbers in an abstract and the amount of citation?  \n",
        "\n",
        "### 4. Classic NLP pipeline\n",
        "#### 4.0 Re-tokenize using spacy\n",
        "#### 4.1 Lemmatize using spacy\n",
        "#### 4.2 POS tagging using spacy, plot the trees\n",
        "#### 4.3 NER using spacy, give the amount of each entity type for a given abstract, and compare it to the amount of citations. \n",
        "\n",
        "### 5. Topic Modelling\n",
        "#### 5.1 Use Gensim's LDA to compute a topic model. \n",
        "#### 5.2 Use PyLDAvis to visualise the topic model. What are the different topic clusters?\n",
        "#### 5.3 Use a tf-idf representation for each abstract, and use your favorite clustering algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "Jsp-VxWQZDwo",
        "outputId": "27b95bfe-b57a-47bf-f5bf-329cffecf582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-27 19:16:10--  https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/01/PLOS_narrativity.csv.zip\n",
            "Résolution de d1p17r2m4rzlbo.cloudfront.net (d1p17r2m4rzlbo.cloudfront.net)… échec : nodename nor servname provided, or not known.\n",
            "wget : impossible de résoudre l’adresse de l’hôte « d1p17r2m4rzlbo.cloudfront.net »\n"
          ]
        }
      ],
      "source": [
        "# Downloading the database\n",
        "!wget https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/01/PLOS_narrativity.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "id": "ubcnJhB-ZW7M",
        "outputId": "6546291a-2913-4809-ec8e-e144346414ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open PLOS_narrativity.csv.zip, PLOS_narrativity.csv.zip.zip or PLOS_narrativity.csv.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip PLOS_narrativity.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Whx0UrMnZ8_I"
      },
      "source": [
        "# 1. Basic preprocessing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j9XMO0rukSUI"
      },
      "source": [
        "\n",
        "## 1.1 Open the database. Generate simple statistics about the abstracts. How many unique articles are there? What is the mean length of abstracts in characters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2aDHInXDZivc"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "zQsYiy5ZZqdM",
        "outputId": "b3ed9078-ed47-4a17-b6d7-944ddc99c9ac"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'PLOS_narrativity.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLOS_narrativity.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape:  \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(df\u001b[38;5;241m.\u001b[39mshape))\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PLOS_narrativity.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('PLOS_narrativity.csv', index_col=0)\n",
        "print(\"Shape:  {0}\".format(df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "H_7iPZvdiQ64",
        "outputId": "7b92cf77-5b03-48b0-e269-ac7a636c80b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "802\n"
          ]
        }
      ],
      "source": [
        "# e.g \n",
        "# Number of different articles in the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "9h_UW9XeigeM",
        "outputId": "b54914f5-0308-4808-d5ae-f5c3d430d188"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1496.1795511221944"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mean length of abstracts in characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "p-T5TPTFjJdo"
      },
      "outputs": [],
      "source": [
        "# Repartition of the abstracts length in characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AIcJZYhYkCa8"
      },
      "source": [
        "## 1.2 Generate simple statistics about the annotators' data for each article. Do the annotations seem consistent? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "colab_type": "code",
        "id": "QRY93UFskERs",
        "outputId": "db03c608-7262-4849-e8ba-97201799d284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['X_unit_id', 'X_created_at', 'X_id', 'X_started_at', 'X_tainted',\n",
              "       'X_channel', 'X_trust', 'X_worker_id', 'X_country', 'X_region',\n",
              "       'X_city', 'X_ip', 'appeal_to_reader', 'conjunctions', 'connectivity',\n",
              "       'narrative_perspective', 'sensory_language', 'setting', 'ab',\n",
              "       'appeal_to_reader_gold', 'conjunctions_gold', 'connectivity_gold',\n",
              "       'narrative_perspective_gold', 'pmid', 'py', 'sensory_language_gold',\n",
              "       'setting_gold', 'so', 'tc', 'af', 'au', 'bp', 'di', 'ep', 'is', 'pd',\n",
              "       'pt', 'sn', 'ti', 'ut', 'vl', 'z9', 'cin_mas', 'firstauthor',\n",
              "       'numberauthors', 'pid_mas', 'title'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First, number of annotator per article\n",
        "# --> X annotators/article\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bdw76Q3WpUrY"
      },
      "outputs": [],
      "source": [
        "# Seing coherence between annotators : need to transform appeal_to_reader, narrative_perspective, setting to bools. \n",
        "# Then, std on the columns. \n",
        "df['appeal_to_reader'] = df.appeal_to_reader.apply(lambda x: True if x==\"yes\" else False)\n",
        "df['narrative_perspective'] = df.narrative_perspective.apply(lambda x: True if x==\"yes\" else False)\n",
        "df['setting'] = df.setting.apply(lambda x: True if x==\"yes\" else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "colab_type": "code",
        "id": "0q9fXWhCt1QI",
        "outputId": "8a957b1e-4455-4874-9cd2-09f175550d7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appeal_to_reader</th>\n",
              "      <th>conjunctions</th>\n",
              "      <th>connectivity</th>\n",
              "      <th>narrative_perspective</th>\n",
              "      <th>sensory_language</th>\n",
              "      <th>setting</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pmid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18726051</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.976047</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.397276</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18783869</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.573592</td>\n",
              "      <td>1.976047</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>1.718249</td>\n",
              "      <td>0.534522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18810525</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.345185</td>\n",
              "      <td>1.799471</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.463850</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18810526</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>2.214670</td>\n",
              "      <td>0.975900</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>1.214986</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18811616</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.069045</td>\n",
              "      <td>1.380131</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>1.069045</td>\n",
              "      <td>0.487950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216227</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.133893</td>\n",
              "      <td>1.718249</td>\n",
              "      <td>0.534522</td>\n",
              "      <td>2.449490</td>\n",
              "      <td>0.377964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216263</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>0.951190</td>\n",
              "      <td>2.340126</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>0.975900</td>\n",
              "      <td>0.487950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216307</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.133893</td>\n",
              "      <td>1.799471</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.380131</td>\n",
              "      <td>0.377964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216315</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.214986</td>\n",
              "      <td>1.253566</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.397276</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22242115</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.463850</td>\n",
              "      <td>2.544836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          appeal_to_reader  conjunctions  ...  sensory_language   setting\n",
              "pmid                                      ...                            \n",
              "18726051          0.487950      1.976047  ...          1.397276  0.000000\n",
              "18783869          0.534522      1.573592  ...          1.718249  0.534522\n",
              "18810525          0.487950      1.345185  ...          1.463850  0.000000\n",
              "18810526          0.487950      2.214670  ...          1.214986  0.000000\n",
              "18811616          0.534522      1.069045  ...          1.069045  0.487950\n",
              "...                    ...           ...  ...               ...       ...\n",
              "22216227          0.487950      1.133893  ...          2.449490  0.377964\n",
              "22216263          0.487950      0.951190  ...          0.975900  0.487950\n",
              "22216307          0.534522      1.133893  ...          1.380131  0.377964\n",
              "22216315          0.534522      1.214986  ...          1.397276  0.000000\n",
              "22242115          0.534522      1.463850  ...          0.487950  0.000000\n",
              "\n",
              "[802 rows x 6 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_cols = [\"appeal_to_reader\", \"conjunctions\", \"connectivity\", \"narrative_perspective\", \"sensory_language\", \"setting\"]\n",
        "df.groupby(df.pmid)[eval_cols].std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "WTMJiivwhivd",
        "outputId": "6a013da4-8048-4481-cf35-bee33f3fdeaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "802"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.pmid.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FWk_CeIewts0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wNv0YjyJ1rhc"
      },
      "source": [
        "# 2. Word-level preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zTGT_vBp1uA0"
      },
      "source": [
        "## 2.1 Split the abstracts into list of words. How many different words are there in the vocabulary?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VdGlmSrSxqLI"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "from operator import add\n",
        "\n",
        "# List of words with separator = \" \"\n",
        "arr = df.ab.drop_duplicates().apply(lambda x: x.split(' ')).array\n",
        "\n",
        "arr = reduce(add, arr)\n",
        "#len(set(arr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YDphQOEC2pUI"
      },
      "source": [
        "## 2.2 Split the abstracts into list of words using three different tokenizers from nltk. What is the difference in terms of number of words? What do you think has changed?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1n5gotzl2m7A"
      },
      "outputs": [],
      "source": [
        "# https://www.nltk.org/api/nltk.tokenize.html \n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "# e.g : tokenizers = [TreebankWordTokenizer(), ToktokTokenizer(), TweetTokenizer()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jkthxY5s5dvA"
      },
      "source": [
        "## 2.3 Check if Zipf's law applies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8bT4E8Oj5cos"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "omVMvmwuBvDk"
      },
      "source": [
        "# 3. Domain specificity and regex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jQ6pLbSlBxpM"
      },
      "source": [
        "## 3.1 Use regex to retrieve numbers (ints, floats, %, years, ...) in abstracts.\n",
        "\n",
        "\n",
        "*Regex cheasheet* : see python's re module documentation https://docs.python.org/3/library/re.html  \n",
        "\n",
        "*Other ressources* : \n",
        "\n",
        "- A good website to write and test regular expressions : \n",
        "https://regex101.com/\n",
        "- A good game to learn regex : https://alf.nu/RegexGolf \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K5LP929Xd7IA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# Regular expression that matches any sequence of numbers:\n",
        "nb =  ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OscHta8ZBz8E"
      },
      "source": [
        "## 3.2 How many percent of characters are numbers (as defined above) in a given abstract?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_y-_GUBvB3Ts"
      },
      "source": [
        "## 3.3 Is there any relationship between the percentage of numbers in an abstract and the amount of citation?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab-1-NLP-ENSAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
